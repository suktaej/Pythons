{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e159b5ea-839e-469a-851b-5bde587bda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ca194f-7e95-491c-8e2d-4ae883e80e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "x_train = tf.reshape(x_train,[-1,28,28,1])\n",
    "x_test = tf.reshape(x_train,[-1,28,28,1])\n",
    "print(x_train.shape) #(60000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a99562f-6f0e-4e97-9da7-7f5c126d2cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,162\n",
      "Trainable params: 113,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),padding='same',\n",
    "                           activation='relu',input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding='same',\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),padding='same',\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(units=10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Xavier Glorot Initialization : W(Weight) 값을 fan_in,fan_out를 사용하여 초기화하여 정확도 향상\n",
    "              \n",
    "# loss 종류\n",
    "# mean_squared_error : 평균제곱 오차\n",
    "# binary_crossentropy : 이진분류 오차\n",
    "# categorical_crossentropy : 다중 분류 오차. one-hot encoding 클래스, [0.2, 0.3, 0.5] 와 같은 출력값과 실측값의 오차값을 계산한다.\n",
    "# sparse_categorical_crossentropy: 다중 분류 오차. 위와 동일하지만 , integer type 클래스라는 것이 다르다.\n",
    "              \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1a2a5f4-11e1-4dad-bac8-8fed18d95ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1407/1407 [==============================] - 7s 4ms/step - loss: 0.8265 - accuracy: 0.8696 - val_loss: 0.1968 - val_accuracy: 0.9376\n",
      "Epoch 2/25\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.2476 - accuracy: 0.9253 - val_loss: 0.2457 - val_accuracy: 0.9294\n",
      "Epoch 3/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.2047 - accuracy: 0.9366 - val_loss: 0.2052 - val_accuracy: 0.9373\n",
      "Epoch 4/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1824 - accuracy: 0.9445 - val_loss: 0.1623 - val_accuracy: 0.9480\n",
      "Epoch 5/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1740 - accuracy: 0.9470 - val_loss: 0.1835 - val_accuracy: 0.9407\n",
      "Epoch 6/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1641 - accuracy: 0.9487 - val_loss: 0.1313 - val_accuracy: 0.9577\n",
      "Epoch 7/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1684 - accuracy: 0.9486 - val_loss: 0.1687 - val_accuracy: 0.9470\n",
      "Epoch 8/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1635 - accuracy: 0.9478 - val_loss: 0.1633 - val_accuracy: 0.9525\n",
      "Epoch 9/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1581 - accuracy: 0.9520 - val_loss: 0.1970 - val_accuracy: 0.9425\n",
      "Epoch 10/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1707 - accuracy: 0.9449 - val_loss: 0.2176 - val_accuracy: 0.9265\n",
      "Epoch 11/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1887 - accuracy: 0.9389 - val_loss: 0.1850 - val_accuracy: 0.9415\n",
      "Epoch 12/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1712 - accuracy: 0.9453 - val_loss: 0.1888 - val_accuracy: 0.9381\n",
      "Epoch 13/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1622 - accuracy: 0.9468 - val_loss: 0.1872 - val_accuracy: 0.9460\n",
      "Epoch 14/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1563 - accuracy: 0.9492 - val_loss: 0.1955 - val_accuracy: 0.9406\n",
      "Epoch 15/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1546 - accuracy: 0.9497 - val_loss: 0.1991 - val_accuracy: 0.9404\n",
      "Epoch 16/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1479 - accuracy: 0.9516 - val_loss: 0.1851 - val_accuracy: 0.9453\n",
      "Epoch 17/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1466 - accuracy: 0.9522 - val_loss: 0.1721 - val_accuracy: 0.9465\n",
      "Epoch 18/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1448 - accuracy: 0.9514 - val_loss: 0.1793 - val_accuracy: 0.9417\n",
      "Epoch 19/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1437 - accuracy: 0.9533 - val_loss: 0.1962 - val_accuracy: 0.9393\n",
      "Epoch 20/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1380 - accuracy: 0.9542 - val_loss: 0.1907 - val_accuracy: 0.9454\n",
      "Epoch 21/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1367 - accuracy: 0.9553 - val_loss: 0.2177 - val_accuracy: 0.9341\n",
      "Epoch 22/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1413 - accuracy: 0.9524 - val_loss: 0.1878 - val_accuracy: 0.9446\n",
      "Epoch 23/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1347 - accuracy: 0.9555 - val_loss: 0.2142 - val_accuracy: 0.9370\n",
      "Epoch 24/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1342 - accuracy: 0.9567 - val_loss: 0.1830 - val_accuracy: 0.9436\n",
      "Epoch 25/25\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1311 - accuracy: 0.9569 - val_loss: 0.2065 - val_accuracy: 0.9427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18b34b419c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=25,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf3baa0-cd7a-4381-958a-acc9de61ac62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 60000\n  y sizes: 10000\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf210\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf210\\lib\\site-packages\\keras\\engine\\data_adapter.py:1851\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1845\u001b[0m         label,\n\u001b[0;32m   1846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m   1847\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1848\u001b[0m         ),\n\u001b[0;32m   1849\u001b[0m     )\n\u001b[0;32m   1850\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1851\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 60000\n  y sizes: 10000\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2a23b-46ad-4e48-a92f-cc2eac2fdc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test[:10])\n",
    "print(tf.argmax(preds,axis=1).numpy()) #예측\n",
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e403f-b1a9-4793-abcc-1b23c18fbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGGNet (VGG-19) 스타일의 MNIST 분류 CNN 모델 \n",
    "#--------------------------------------------\n",
    "# ( Conv2D * 2개  --> MaxPool2D ) * 2회 : 4층\n",
    "# ( Conv2D * 4개  --> MaxPool2D ) * 3회 : 12층\n",
    "# Dense * 3개                           : 3층\n",
    "#--------------------------------------------\n",
    "#                                     총 19층\n",
    "#--------------------------------------------\n",
    "# 각 네트워크마다 필터의 수를 2배로 증가 시킨다 : 32-->64-->128-->256-->512\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),padding='same',\n",
    "                           activation='relu',input_shape=(28,28,1)),\n",
    "    tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding='same',\n",
    "                           activation='relu'),  \n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),padding='same',\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),padding='valid',\n",
    "                           activation='relu'),  \n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "\n",
    "    tf.keras.layers.Flatten(),  \n",
    "    tf.keras.layers.Dense(units=512,activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(units=256,activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(units=10,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b8c074-5d72-4a42-8eac-c54db613d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "model.fit(x_train,y_train,epochs=25,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb7598d-25c0-41a0-8abc-9bd52b4998fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ce7de-99ea-45b2-a70e-2c62e66cbab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
